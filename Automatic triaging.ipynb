{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Health, You decide (But decide wisely for the rest of us please)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey let me tell you somethin you might wanna hear.\n",
    "\n",
    "Hospital workers are inundated with many patients who now have the Coronavirus, not to mention sewing masks for themselves, caring for their other quarantined family members etc.,. So, to make everyone's life a little better, please ask yourself: Should I really be going out there to my doctor's clinic or a hospital?\n",
    "\n",
    "Who knows? You might walk in for precautionary measures without the virus, get to the medical facility, contract the virus from another patient. You could add to a doctor's headaches. So here we are. You're torn about what to do. Well, relax. Let's think about this rationally and make the best decision for you.\n",
    "\n",
    "Here we have a multi-level classifier which will group you into different categories of risk and decide whether it's best if you go to a hospital, or stay home and keep a watch on your health status, or just sit tight. (DISCLAIMER: These lines of code do not and should not dictate your choices/course of action. Make sure to check in with your doctor on the phone about any decision you make that relates to this crisis. Plus, who am I to tell you what to do? So, choose for yourself. I hope for all our sakes that you end up making the right choice.)\n",
    "\n",
    "This is a prototype classifier that is not trained with a lot of symptoms taken into consideration. A new release where all the ailments of every COVID-19 patient are taken into consideration and evaluated for relevance using a Bayesian Network will be released. The new release should hopefully cover all symptoms and be (near-)completely comprehensive in triaging you into a risk category. More hopefully, this whole thing blows over before I release that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Do not import any other libraries other than those listed here. \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "import seaborn as sns\n",
    "import keras\n",
    "import keras.utils\n",
    "from keras import utils as np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, neighbors\n",
    "import sklearn.datasets \n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DGP():\n",
    "    symptoms = 'pid,fever,tiredness,dry_cough,breathing_difficulty,ache_somewhere,nasal_congestion,runny_nose,sore_throat,diarrhea,hospital_need'\n",
    "    data = np.random.randint(2, size = (1001, 9))\n",
    "    hosp = np.random.randint(3, size = 1000)\n",
    "    data = np.append(data, [hosp], axis = 1)\n",
    "    data = np.insert(data, [0], np.arange(1,1001), axis=1)\n",
    "    for i in range(len(data)-1):\n",
    "        line = data[i]\n",
    "        for symptom in symptoms.split(','):\n",
    "            if symptom == 'breathing_difficulty' and line[4] == 1:\n",
    "                line[-1] = 2\n",
    "                line[1] = 1\n",
    "            if symptom == 'fever' and line[1] == 1:\n",
    "                line[-1] = 2\n",
    "        if line[:len(line)] == [i, 0, 0, 0, 0, 0, 0, 0, 0, 0]:\n",
    "            line[-1] = 0\n",
    "        else:\n",
    "            if line[-1] != 2:\n",
    "                line[-1] = 1\n",
    "        line = np.asarray(line)\n",
    "        data[i] = [line]\n",
    "    data = np.asarray(data)\n",
    "    print(data)\n",
    "    df = pd.DataFrame(data = data, index = np.arange(1,1000), columns = symptoms.split(','))\n",
    "    X = df[['pid', 'fever','tiredness','dry_cough','breathing_difficulty','ache_somewhere','nasal_congestion','runny_nose','sore_throat','diarrhea']].values\n",
    "    Y = df['hospital need']\n",
    "    \n",
    "    #test_size can change as more updates reveal more features. Currently 9 major symptoms listed on WHO website are the focus,\n",
    "    #the ones that the WHO recommends hospitalization for are the ones with hospital need = 2. \n",
    "    #test_size proportion = sqrt(1/number of features) = sqrt(1/9) = 1/3\n",
    "    \n",
    "    x_train, x_val, y_train, y_val = train_test_split(X,Y, test_size=0.33, random_state = 0)\n",
    "    \n",
    "    return x_train, x_val, y_train, y_val\n",
    "\n",
    "x_train, y_train, x_val, y_val = DGP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For a sanity check, we use the K-nearest neighbors method to group patients into triages. We check the accuracy.\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "training_accuracy = 0\n",
    "index = 0\n",
    "for elem in y_train:\n",
    "    if model.predict([x_train[index]]) == elem:\n",
    "        training_accuracy += 1\n",
    "    index += 1\n",
    "training_accuracy = float(training_accuracy/len(y_train))\n",
    "print('accuracy of training data inputs: '+str(training_accuracy))\n",
    "\n",
    "val_acc = 0\n",
    "index = 0\n",
    "for elem in y_val:\n",
    "    if model.predict([x_val[index]]) == elem:\n",
    "        val_acc += 1\n",
    "    index += 1\n",
    "val_acc = float(val_acc/len(y_val))\n",
    "print('accuracy of validation data inputs: '+str(val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are 9 symptoms, I think a reasonable neural network will have 81 nodes in the input and hidden layers (I mean we start asking questions once we have 2 minor symptoms, but hopefully it learns the rule that the WHO recommends: call a doctor if you have a fever and/or breathing difficulty). To assess the accuracy, there will be long pages of tests where I tweak the number of nodes in a layer, number of layers. The activation function needs to be reLU since the classification is not binary and we want better accuracy with little training time to afford."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val = DGP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define an abstracted function since we will be testing a variety of input sizes and number of layers to see which one is best\n",
    "#\n",
    "def NN_model(layers, input_count):\n",
    "    model = Sequential()\n",
    "    for i in range(layers):\n",
    "        model.add(Dense(input_count, input_dim = input_count, activation = 'relu'))\n",
    "        model.add(Dropout(0.1))\n",
    "    model.add(Dense(3, input_dim = input_count, activation = 'relu'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We try a network with an input and an output layer to see how it works for a start. We will build on this and try out many\n",
    "#more combinations with new randomly-generated data for each trial. So our network will not be overfitted.\n",
    "#Yet we are looking for the best of many random trials, so we are effectively chasing the maximum for all data.\n",
    "\n",
    "model1 = NN_model(1, 81)\n",
    "model1.fit(x_train, y_train, epochs = 12, batch_size = 81, verbose = True)\n",
    "print(model1.evaluate(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accs = []\n",
    "n_vals = []\n",
    "for n in range(1, 11, 1):\n",
    "    n_vals.append(n)\n",
    "    i_vals = []\n",
    "    for i in range(1, 729, 81):\n",
    "        #DGP\n",
    "        model2 = NN_model(n, i)\n",
    "        model2.fit(x_train, y_train, epochs = 12, batch_size = 81, verbose = True)\n",
    "        test_accs.append(model2.evaluate(x_val, y_val)[1])\n",
    "        print(str(n)+\" layer network:\")\n",
    "        plt.scatter(i_vals, test_accs)\n",
    "#plt.scatter(n_vals, test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of layers and inputs for which the accuracy is highest is ___ based on all the scatter plots. The values for which the accuracy was closest to 1 is the one that works best for randomly generated patient data. Our algorithm learns the WHO recommendation rule as quickly as that. Similarly when more data becomes available and easily machine-readable, the new release will also have a lot of simulations like these to find the best fitting network structure.\n",
    "\n",
    "But for now, we're gonna try another 1000 values and see how it does just as a sanity check on our prototype."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
